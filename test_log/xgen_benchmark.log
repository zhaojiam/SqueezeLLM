No CUDA runtime is found, using CUDA_HOME='/rdrive/ref/cuda/lin/cuda-12.4'
models/xgen-7b-8k-base
name1  model.layers.0.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.0.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.0.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.0.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.0.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.0.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.0.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.1.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.1.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.1.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.1.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.1.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.1.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.1.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.2.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.2.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.2.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.2.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.2.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.2.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.2.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.3.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.3.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.3.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.3.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.3.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.3.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.3.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.4.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.4.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.4.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.4.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.4.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.4.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.4.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.5.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.5.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.5.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.5.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.5.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.5.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.5.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.6.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.6.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.6.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.6.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.6.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.6.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.6.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.7.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.7.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.7.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.7.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.7.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.7.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.7.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.8.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.8.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.8.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.8.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.8.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.8.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.8.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.9.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.9.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.9.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.9.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.9.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.9.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.9.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.10.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.10.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.10.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.10.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.10.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.10.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.10.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.11.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.11.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.11.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.11.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.11.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.11.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.11.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.12.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.12.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.12.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.12.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.12.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.12.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.12.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.13.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.13.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.13.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.13.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.13.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.13.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.13.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.14.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.14.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.14.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.14.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.14.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.14.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.14.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.15.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.15.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.15.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.15.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.15.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.15.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.15.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.16.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.16.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.16.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.16.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.16.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.16.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.16.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.17.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.17.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.17.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.17.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.17.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.17.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.17.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.18.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.18.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.18.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.18.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.18.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.18.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.18.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.19.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.19.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.19.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.19.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.19.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.19.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.19.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.20.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.20.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.20.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.20.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.20.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.20.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.20.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.21.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.21.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.21.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.21.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.21.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.21.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.21.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.22.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.22.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.22.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.22.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.22.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.22.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.22.mlp.up_proj
2024-06-24 19:08:32,116 - datasets - INFO - PyTorch version 2.1.0.post2+cxx11.abi available.
Using unk_token, but it is not set yet.
Using unk_token, but it is not set yet.
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.23.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.23.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.23.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.23.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.23.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.23.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.23.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.24.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.24.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.24.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.24.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.24.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.24.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.24.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.25.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.25.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.25.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.25.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.25.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.25.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.25.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.26.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.26.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.26.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.26.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.26.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.26.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.26.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.27.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.27.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.27.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.27.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.27.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.27.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.27.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.28.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.28.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.28.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.28.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.28.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.28.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.28.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.29.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.29.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.29.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.29.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.29.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.29.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.29.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.30.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.30.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.30.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.30.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.30.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.30.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.30.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.31.self_attn.k_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.31.self_attn.o_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.31.self_attn.q_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.31.self_attn.v_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.31.mlp.down_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.31.mlp.gate_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
name1  model.layers.31.mlp.up_proj
self.rows:  tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)
Loading model ...
Done.
Model type : llama
Benchmarking ...
0 0.4043407440185547
1 0.04563331604003906
2 0.042763710021972656
3 0.041530609130859375
4 0.041823387145996094
5 0.041554927825927734
6 0.04132485389709473
7 0.04116010665893555
8 0.04135918617248535
9 0.0572664737701416
10 0.041181325912475586
11 0.0412750244140625
12 0.041333913803100586
13 0.0416104793548584
14 0.041535139083862305
15 0.04163861274719238
16 0.041441917419433594
17 0.041635990142822266
18 0.04134726524353027
19 0.0414423942565918
20 0.041480064392089844
21 0.0416264533996582
22 0.04141950607299805
23 0.04164314270019531
24 0.04174089431762695
25 0.041738271713256836
26 0.041480302810668945
27 0.0416874885559082
28 0.041414499282836914
29 0.0414576530456543
30 0.041706085205078125
31 0.04113364219665527
32 0.04153561592102051
33 0.04187774658203125
34 0.04138016700744629
35 0.04154539108276367
36 0.04164528846740723
37 0.04152560234069824
38 0.04185676574707031
39 0.04180908203125
40 0.04199647903442383
41 0.042092084884643555
42 0.0419926643371582
43 0.04198718070983887
44 0.04146909713745117
45 0.04171609878540039
46 0.04195046424865723
47 0.041835784912109375
48 0.04178023338317871
49 0.04142284393310547
50 0.04188990592956543
51 0.04186201095581055
52 0.04179549217224121
53 0.04172635078430176
54 0.041790008544921875
55 0.04165506362915039
56 0.041756391525268555
57 0.04220008850097656
58 0.04218912124633789
59 0.04201245307922363
60 0.041815757751464844
61 0.042006731033325195
62 0.042054176330566406
63 0.04192233085632324
64 0.04210662841796875
65 0.04186511039733887
66 0.04202866554260254
67 0.04219961166381836
68 0.04183316230773926
69 0.041947126388549805
70 0.0419774055480957
71 0.04190850257873535
72 0.04181051254272461
73 0.04194188117980957
74 0.04185914993286133
75 0.041846513748168945
76 0.04198479652404785
77 0.041867971420288086
78 0.04186439514160156
79 0.0418703556060791
80 0.04166436195373535
81 0.041825294494628906
82 0.04212498664855957
83 0.04189777374267578
84 0.04202985763549805
85 0.04208660125732422
86 0.04169797897338867
87 0.04167342185974121
88 0.041877031326293945
89 0.04209017753601074
90 0.04206657409667969
91 0.04183077812194824
92 0.04202151298522949
93 0.042168617248535156
94 0.04226517677307129
95 0.04198575019836426
96 0.04217529296875
97 0.041681528091430664
98 0.04211235046386719
99 0.04243803024291992
100 0.04230165481567383
101 0.04213595390319824
102 0.042110443115234375
103 0.0419309139251709
104 0.041840553283691406
105 0.04194903373718262
106 0.04224729537963867
107 0.04184317588806152
108 0.042176008224487305
109 0.04219985008239746
110 0.042151689529418945
111 0.042298078536987305
112 0.04232358932495117
113 0.042359113693237305
114 0.042428016662597656
115 0.04213380813598633
116 0.042166709899902344
117 0.04220771789550781
118 0.04231429100036621
119 0.04221653938293457
120 0.0423431396484375
121 0.04267454147338867
122 0.042371273040771484
123 0.042513132095336914
124 0.04240751266479492
125 0.04247927665710449
126 0.04243183135986328
127 0.04573464393615723
Median: 0.0418773889541626
PPL: 165962.78125
max memory(MiB): 4629.5302734375
