(sqllm) zhaojiam@jfnb-spr-100477:~/SqueezeLLM$ python llama.py models/llama-2-7b c4 --wbits 3 --load sq-llama-2-7b-w3-s0.pt --benchmark 128 --check
No CUDA runtime is found, using CUDA_HOME='/rdrive/ref/cuda/lin/cuda-12.4'
2.1.0.post2+cxx11.abi
2.1.30.post0
[0]: _DeviceProperties(name='Intel(R) Data Center GPU Max 1100', platform_name='Intel(R) Level-Zero', dev_type='gpu', driver_version='1.3.29138', has_fp64=1, total_memory=49152MB, max_compute_units=448, gpu_eu_count=448)
models/llama-2-7b
Loading model ...
Done.
2024-06-11 08:01:15,631 - datasets - INFO - PyTorch version 2.1.0.post2+cxx11.abi available.
Model type : llama
Benchmarking ...
0 2.7106754779815674
1 0.03295779228210449
2 0.028235435485839844
3 0.028509855270385742
4 0.02857208251953125
5 0.027480363845825195
6 0.02781534194946289
7 0.02789020538330078
8 0.027796506881713867
9 0.0442967414855957
10 0.028057575225830078
11 0.0274505615234375
12 0.027830123901367188
13 0.028190135955810547
14 0.027681589126586914
15 0.02735614776611328
16 0.027794837951660156
17 0.027590274810791016
18 0.027731657028198242
19 0.02741074562072754
20 0.027628660202026367
21 0.027818679809570312
22 0.02729177474975586
23 0.027258872985839844
24 0.027724504470825195
25 0.027808427810668945
26 0.027463197708129883
27 0.027115583419799805
28 0.02713918685913086
29 0.02757096290588379
30 0.02726149559020996
31 0.0273592472076416
32 0.02851724624633789
33 0.027486085891723633
34 0.02697896957397461
35 0.02717423439025879
36 0.02706003189086914
37 0.02739095687866211
38 0.028029441833496094
39 0.02743363380432129
40 0.02716207504272461
41 0.02728438377380371
42 0.02985095977783203
43 0.027635574340820312
44 0.027398109436035156
45 0.02928471565246582
46 0.02809762954711914
47 0.027510404586791992
48 0.02723240852355957
49 0.027335643768310547
50 0.02737140655517578
51 0.02767324447631836
52 0.027322769165039062
53 0.027057647705078125
54 0.029634475708007812
55 0.027682065963745117
56 0.027431011199951172
57 0.027271270751953125
58 0.02730536460876465
59 0.027359485626220703
60 0.02768540382385254
61 0.027184247970581055
62 0.029893875122070312
63 0.027706623077392578
64 0.02785944938659668
65 0.027368783950805664
66 0.027123212814331055
67 0.027402162551879883
68 0.02723979949951172
69 0.027744054794311523
70 0.02727365493774414
71 0.027250051498413086
72 0.027099132537841797
73 0.027336597442626953
74 0.02733635902404785
75 0.027349472045898438
76 0.027257442474365234
77 0.027153968811035156
78 0.02758646011352539
79 0.027128934860229492
80 0.02710890769958496
81 0.027317285537719727
82 0.02777576446533203
83 0.027465105056762695
84 0.02729654312133789
85 0.027138710021972656
86 0.027342796325683594
87 0.027689456939697266
88 0.027215003967285156
89 0.02726578712463379
90 0.02723217010498047
91 0.027705907821655273
92 0.027231693267822266
93 0.027250051498413086
94 0.027206897735595703
95 0.02733469009399414
96 0.02770233154296875
97 0.027267932891845703
98 0.027220964431762695
99 0.02716541290283203
100 0.027607440948486328
101 0.027147293090820312
102 0.027198314666748047
103 0.02716374397277832
104 0.027238130569458008
105 0.027491092681884766
106 0.027051925659179688
107 0.02714085578918457
108 0.027139902114868164
109 0.027550935745239258
110 0.027138948440551758
111 0.02724933624267578
112 0.027060270309448242
113 0.027468204498291016
114 0.027151823043823242
115 0.027116060256958008
116 0.027292251586914062
117 0.02727985382080078
118 0.027523040771484375
119 0.0271151065826416
120 0.02782750129699707
121 0.0275728702545166
122 0.027529001235961914
123 0.02718830108642578
124 0.02706170082092285
125 0.026970863342285156
126 0.027025938034057617
127 0.03151106834411621
Median: 0.027359366416931152
PPL: 7029.42041015625
max memory(MiB): 0

